{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eaf31fdd",
   "metadata": {},
   "source": [
    "Test to chunk and make embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5e50a66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_community.embeddings import SentenceTransformerEmbeddings\n",
    "from langchain.schema import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45b00c0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name          0\n",
      "Region        0\n",
      "SumUp         0\n",
      "Biography     0\n",
      "Story        31\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "##searching if their is missing data in the csv\n",
    "##missing 31 stories because riot still doesn't wrote it \n",
    "df = pd.read_csv(\"../data/raw/lore.csv\")\n",
    "print(df.isnull().sum())\n",
    "null_data = df[df.isnull().any(axis=1)]\n",
    "df.fillna(\"L'éditeur Riot Games n'a pas encore fourni l'histoire de ce champion\", inplace = True)\n",
    "#df\n",
    "#null_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc9595a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': None,\n",
       " 'metadata': {'Source': 'Biography',\n",
       "  'Name': 'AATROX',\n",
       "  'Region': 'RUNETERRA',\n",
       "  'Sum_up': \"Autrefois, Aatrox et ses frères étaient honorés pour avoir défendu Shurima contre le Néant. Mais ils finirent par devenir une menace plus grande encore pour Runeterra : la ruse et la sorcellerie furent employées pour les battre. Cependant, après des siècles d'emprisonnement, Aatrox fut le premier à retrouver sa liberté, en corrompant et transformant les mortels assez stupides pour tenter de s'emparer de l'arme magique qui contenait son essence. Désormais en possession d'un corps qu'il a approximativement transformé pour rappeler son ancienne forme, il arpente Runeterra en cherchant à assouvir sa vengeance apocalyptique.\"},\n",
       " 'page_content': \"Shurima fut conduit devant le Disque solaire pour devenir l'avatar d'une entité céleste aujourd'hui oubliée. Transfiguré, il obtint des ailes dorées comme la lumière de l'aube. Son armure étincelait comme une constellation d'espoir d'au-delà du grand voile. Aatrox était son nom. Il était à\",\n",
       " 'type': 'Document'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=300,\n",
    "    chunk_overlap=30,\n",
    "    length_function=len,\n",
    "    is_separator_regex=False,\n",
    ")   \n",
    "\n",
    "liste_chunk = []\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    text_biography = row['Biography']\n",
    "    text_story = row['Story']\n",
    "    texts_bio = text_splitter.create_documents([text_biography],[{\"Source\": \"Biography\", \"Name\": row['Name'], \"Region\": row['Region'], \"Sum_up\": row['SumUp']}])\n",
    "    text_story = text_splitter.create_documents([text_story], [{\"Source\": \"Story\", \"Name\": row['Name'], \"Region\": row['Region'], \"Sum_up\": row['SumUp']}])\n",
    "    liste_chunk.extend(texts_bio)\n",
    "    liste_chunk.extend(text_story)\n",
    "\n",
    "\n",
    "liste_chunk[1].__dict__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "268abad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/processed/lore_chunked.csv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "578bce77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bapti\\AppData\\Local\\Temp\\ipykernel_1392\\590564233.py:1: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embedding_model = SentenceTransformerEmbeddings(\n",
      "d:\\Programmation\\environnement_python\\rag\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "d:\\Programmation\\environnement_python\\rag\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\bapti\\.cache\\huggingface\\hub\\models--sentence-transformers--paraphrase-multilingual-MiniLM-L12-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre total de vecteurs : 7792\n"
     ]
    }
   ],
   "source": [
    "embedding_model = SentenceTransformerEmbeddings(\n",
    "        model_name=\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\"\n",
    "    )\n",
    "vectorstore = FAISS.load_local(\"../data/vectorstores/faiss_index\", embedding_model, allow_dangerous_deserialization=True)\n",
    "print(\"Nombre total de vecteurs :\", vectorstore.index.ntotal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a3ddfd",
   "metadata": {},
   "source": [
    "We split the user_query and use rapid fuzz token ratio to filter on the champion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c3b68fdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AATROX'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rapidfuzz import process, fuzz\n",
    "\n",
    "user_query = \"C'est quoi l'histoire de atrox\"  \n",
    "splitted_input = user_query.split()\n",
    "all_names = df[\"Name\"].unique()\n",
    "\n",
    "for element in splitted_input:\n",
    "    best_match_name, score, _ = process.extractOne(element.upper(), all_names, scorer=fuzz.token_ratio)\n",
    "    if score > 90:\n",
    "        champion_detected = best_match_name\n",
    "\n",
    "champion_detected\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d75d3730",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks_for_champion = df[df[\"Name\"] == champion_detected]\n",
    "\n",
    "# Créer un vectorstore temporaire pour ce champion\n",
    "vectorstore_filtered = FAISS.from_documents(\n",
    "    [Document(page_content=row[\"page_content\"], metadata=row.to_dict())\n",
    "     for _, row in chunks_for_champion.iterrows()],\n",
    "    embedding_model\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "673b72d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "porteur d'épée. D'un meilleur réceptacle. Autour de moi, il n'y a que des morts et des agonisants. J'entends leurs âmes se retirer de ce monde. Le combat n'a pas pris fin. Il continue dans l'enceinte \n",
      "déchus soient aussi dangereux pour la survie de Runeterra que les incursions du Néant, les Targoniens intervinrent. On prétend que la Manifestation du crépuscule donna aux mortels la connaissance néce\n",
      "Qu'on la prenne pour un dieu ou pour un démon, l'Épée des Darkin a fait l'objet de nombreux contes... mais peu connaissent son nom véritable ou l'histoire de sa chute. Aux temps les plus reculés, avan\n",
      "mes hôtes. Les ténèbres. Il pleuvait pendant la bataille. Et si la boue me recouvre ? Si je suis enfoui pendant des milliers d'années ? Enfermé dans cette prison ? L'horreur de cette perspective nourr\n",
      "et la haine grandirent dans son cœur. Les puissances célestes qu'Aatrox avait autrefois incarnées avaient été balayées de ce monde et du souvenir des hommes. Furieux contre cette injustice, Aatrox eut\n",
      "un naufragé qui cherche à regagner la surface en grimpant sur les autres marins. « Que se passe-t-il ?! » hurle le mortel. Mais les ténèbres le réduisent au silence. Les ténèbres éternelles auxquelles\n",
      "toute vie devant lui. Après des années de combats désespérés, Aatrox et ses frères arrêtèrent enfin l'avancée du Néant et scellèrent les failles les plus larges d'où il se déversait. Mais les Transfig\n",
      "en l'espace d'un souffle. Il découvrit qu'au combat, il pouvait se repaître de ses victimes pour se rendre encore plus fort et plus imposant. Aatrox arpenta les plus vastes territoires, cherchant sans\n",
      "Transfigurés se retournèrent les uns contre les autres dans ce qui devint rapidement une guerre pour les ruines de leur propre monde. Les mortels qui fuyaient le conflit leur donnèrent un autre nom po\n",
      "Je supplie les ténèbres sans fin, mais ma requête humiliante ne reçoit que le silence pour réponse. Et soudain… Je sens la présence proche d'un mortel. Je n'ai pas d'yeux, pas d'oreilles, mais je sens\n"
     ]
    }
   ],
   "source": [
    "results = vectorstore_filtered.similarity_search(user_query, k=10)\n",
    "print(len(results))\n",
    "for r in results:\n",
    "    print(r.page_content[:200])  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aee6f3a",
   "metadata": {},
   "source": [
    "Concatenate all the result to build a context for the RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a89e5294",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_chunk = \"\\n\".join([r.page_content for r in results])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf3b2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from mistralai import Mistral\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.environ.get(\"MISTRAL_API_KEY\") ## get the api key using the .env hidden file\n",
    "client = Mistral(api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ac55fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "Le contexte de la question est en dessous.\n",
    "---------------------\n",
    "{retrieved_chunk}\n",
    "---------------------\n",
    "Tu es un expert geek et connais tout l'histoire du jeu League of Legends. En t'appuyant sur le contexte la question et de la question posée, peux tu répondres de façon claire et concise.\n",
    "Query: {user_query}\n",
    "Answer:\n",
    "\"\"\"\n",
    "#prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "debb5c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_mistral(user_message, model=\"mistral-large-latest\"):\n",
    "\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\", \"content\": user_message\n",
    "        }\n",
    "    ]\n",
    "    chat_response = client.chat.complete(\n",
    "        model=model,\n",
    "        messages=messages\n",
    "    )\n",
    "    return (chat_response.choices[0].message.content)\n",
    "\n",
    "run_mistral(prompt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
